{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**<div align=\"center\"><p>CEV & BEBKA - VERİ BİLİMCİ YETİŞTİRME PROGRAMI 2</p> </div>**\n",
        "**<div align=\"center\"><p>CAPSTONE PROJECT</p> </div>**\n",
        "**<div align=\"center\"><p>Face Tracking of Drivers Using YOLOv5 and Estimating Probability of Car Crash by Training Emotion, Age and Eye Condition Models</p> </div>**\n",
        "**<div align=\"center\"><p>Muhammed Erkam KÜÇÜKÇIRAK</p> </div>**\n",
        "\n"
      ],
      "metadata": {
        "id": "QUTShS3ZYCGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>1. ABSTRACT</h1><p>Nowadays, the number of traffic accidents is quite high.\n",
        "Most of them depends on drivers attention. Emotions, age and drowsiness might cause a car accident.  In this project, a solution was applied using cameras where had been placed inside the cars. The method of detecting drowsiness might prevent accidents. In order to achieve this, YOLOv5 and CNN models was used. Even though it is hard to work with facial datasets, the models had high accuracy values  </p>\n",
        "\n"
      ],
      "metadata": {
        "id": "w5PS6hbuW-6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>2. RELATED WORKS</h1>\n",
        "<p>Danisman et al. [1] started with the detection of the face using the Viola Jones [2] face detector available in the OpenCV library. Then, they used the neural network-based eye detector [3] available in the STASM [4] library to locate the positions of the pupils. The STASM is a variation of the Active Shape Model of Coote's implementation [5]. They derived only the Rowley's eye detection code for real-time speed constraints from the STASM library which is a group of neural networks that provides eye positions.</p>\n",
        "<p> Yang et al. [6] declated the size of input image as 416∗416. After a series of convolution and batch normalization operations on the input image, the input image is sampled three times, 32 times, 16 times and 8 times, and the multi-scale feature map is obtained. After 32 times down sampling, the feature map is too small, therefore YOLO V3 uses the up sampling with step size of2 to double the size of the resulting feature map, which becomes 16 times of down sampling. Similarly, the feature map sampled on 16 times is sampled with a step length of2, and the feature map with a sampling size of 8 times is obtained, so that deep feature can be used for detection.</p>\n"
      ],
      "metadata": {
        "id": "LFBfDkEa4nF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> 3. DATASETS </h1>\n",
        "<h2> 3.1. Crash Dataset</h2>\n",
        "<p> A crash dataset [7] was used in order to analyze the effect of age on accidents.</p>"
      ],
      "metadata": {
        "id": "3aHmaOIS8XDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/PERSON.csv\")\n",
        "df = data.AGE.value_counts()\n",
        "df = df.to_frame().reset_index()\n",
        "df.rename(columns={\"index\": \"Age\", \"AGE\": \"Frequency\"}, inplace = True)\n",
        "df = df[df['Age'] >= 18]\n",
        "df = df.sort_values('Age')\n",
        "abc = data.AGE.value_counts('Age')\n",
        "plt.bar(df['Age'], df['Frequency'], color ='maroon',width = 0.4) \n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Number of Accidents\")\n",
        "plt.title(\"Accidents of People of Specific Ages\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "3O3Bb1ME93RF",
        "outputId": "69895814-fb52-429b-df48-073e8868c800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (6,9,10,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>3.2. Age Dataset</h2>\n",
        "<p> UTKFace dataset [8] was used in order to extract features and specify driver's age. UTKFace dataset is a large-scale face dataset with long age span (range from 0 to 116 years old). The dataset consists of over 20,000 face images with annotations of age, gender, and ethnicity.</p>"
      ],
      "metadata": {
        "id": "LJJuIMZOANiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>3.3. Eye Dataset</h2> <p>Closed Eyes In The Wild (CEW) dataset [9] was used in order to detect if driver's eyes are open or close.</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "-7AWotWRKZaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>3.4. Emotion Dataset</h2>\n",
        "<p>FER-2013 Dataset [10] was used in order to detect driver's emotion. </p>"
      ],
      "metadata": {
        "id": "w9TimbniLhBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>3.5. Human Dataset</h2>\n",
        "<p>CrowdHuman dataset [11] was used in order to detect faces from images using YOLOv5.</p>"
      ],
      "metadata": {
        "id": "KRQl5J6KMNUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>4. USED METHODOLOGY</h2>\n",
        "<p>This project includes 3 CNN models and 1 YOLOv5 model. To classify age, eye and emotion; VGG19 (by Transfer Learning), Custom CNN model and VGG16 (by Transfer Learning) was used to train CNN models respectively. </p>"
      ],
      "metadata": {
        "id": "Gwj0cxXWMxBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>This code uploads the weights of trained VGG19 Transfer Learning model on the age dataset. It will be used in order to classify age of drivers.</p>"
      ],
      "metadata": {
        "id": "QUw7EuTW4RiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Load the weights of age classification model.\n",
        "\n",
        "\"\"\"\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "json_file = open(r\"/content/age_modelvgg19.json\", 'r')\n",
        "loaded_model_json1 = json_file.read()\n",
        "json_file.close()\n",
        "age_model = model_from_json(loaded_model_json1)\n",
        "# load weights into new model\n",
        "age_model.load_weights(r\"/content/age_modelvgg19.h5\")\n",
        "age_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "zAIlIEpJO56H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>This code uploads the weights of trained VGG16 Transfer Learning model on the eye dataset. It will be used in order to classify driver's eye status (open or close).</p>\n"
      ],
      "metadata": {
        "id": "UJ02hMNn4_bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Load the weights of eye classification model.\n",
        "\"\"\"\n",
        "json_file = open(r\"/content/eye_model.json\", 'r')\n",
        "loaded_model_json2 = json_file.read()\n",
        "json_file.close()\n",
        "eye_VGG16_tl = model_from_json(loaded_model_json2)\n",
        "\n",
        "# load weights into new model\n",
        "eye_VGG16_tl.load_weights(r\"/content/eye_model.h5\")\n",
        "eye_VGG16_tl.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6BwHLVOUN9ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>This code uploads the weights of trained custom CNN model on the emotion dataset. It will be used in order to classify driver's eye status (open or close).</p>"
      ],
      "metadata": {
        "id": "9ykTtf1M5kBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Load the weights of emotion classification model.\n",
        "\"\"\"\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "json_file = open(r\"/content/model_emotion.json\", 'r')\n",
        "loaded_model_json3 = json_file.read()\n",
        "json_file.close()\n",
        "emotion_model = model_from_json(loaded_model_json3)\n",
        "# load weights into new model\n",
        "emotion_model.load_weights(r\"/content/model_emotion.h5\")\n",
        "emotion_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xedr5KOgPF65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>5. FINAL PRODUCT DEMO</h1>\n",
        "<p>There is an original video and an annotated demo video if you do not prefer to run this .ipynb file. If you want to run this notebook on your computer, please change the file path areas for your own computer. If you want to run this file on Google Colab, just upload the all files. This code will generate the annotated video automatically. When it's done, the only thing that needed to be done is downloading the output video on your computer. </p>"
      ],
      "metadata": {
        "id": "txSSalbXQh2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>This codes process the cropped image (human head) by YOLOv5 model for CNN models to predict that which class shall that image to be in.</p>"
      ],
      "metadata": {
        "id": "4dZ1614g6IGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def pre_procces_for_eye(frame):\n",
        "    image = cv2.resize(frame, (150,150)) \n",
        "    image = np.array(image).reshape(-1,150,150,3)\n",
        "    image = image.astype(\"float32\")\n",
        "    image/= 255.0\n",
        "    return image"
      ],
      "metadata": {
        "id": "xTjPS1OsRmVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_procces_for_age(frame):\n",
        "    image = cv2.resize(frame, (180,180))\n",
        "    image = np.array(image).reshape(-1,180,180,3)\n",
        "    image = image.astype(\"float32\")\n",
        "    image/= 255.0\n",
        "    return image"
      ],
      "metadata": {
        "id": "zpubPZK1Rnib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_procces_for_emotion(frame):\n",
        "    image = cv2.resize(frame, (48,48))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    image = np.array(image).reshape(-1,48,48,1)\n",
        "    image = image.astype(\"float32\")\n",
        "    image/= 255.0\n",
        "    return image"
      ],
      "metadata": {
        "id": "1NPJQOalRnsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>By this codes, all the trained models are going to work simultaneously. This code is going to obtain ROI (Region Of Interest) of the image and crop it. The cropped image's going to be classified by 3 CNN models. After that, results going to be combined on accident probability. If you want to test the model by the videos that you want to, set the file path for it's own path.</p>"
      ],
      "metadata": {
        "id": "52mT-DbR7gDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = r\"/content/best3.pt\"\n",
        "model_face_yolo = torch.hub.load('ultralytics/yolov5', 'custom', PATH)\n",
        "cap = cv2.VideoCapture(r\"/content/original.mp4\")\n",
        "eye_dictionary = {0:\"Open\", 1:\"Close\"}\n",
        "age_dictionary = {0:[\"18-24\",0.3], 1: [\"25-45\",0.2], 2: [\"45+\",0.1]}\n",
        "emotion_dictionary = {0: [\"Negative\",0.3], 1:[\"Positive\",0.2]}\n",
        "\n",
        "width= int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "writer= cv2.VideoWriter(r\"/content/annotated_demo_by_exec.mp4\", cv2.VideoWriter_fourcc(*'DIVX'), 20, (width,height))\n",
        "\n",
        "i=0\n",
        "temp_li=[]\n",
        "FPS= int(cap.get(cv2.CAP_PROP_FPS))\n",
        "drowsy_queue = []\n",
        "sleeping_queue = []"
      ],
      "metadata": {
        "id": "lbVwbpjNCfci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "    ret, frame = cap.read() \n",
        "    if ret == False: break\n",
        "\n",
        "    face_result = model_face_yolo(frame)\n",
        "    try:\n",
        "        boxes = face_result.xyxy[0].numpy()\n",
        "        people_x2y2 = np.sum(boxes[:,2:4], axis=1)\n",
        "        index_of_driver = np.argmax(people_x2y2)\n",
        "        x0, y0, x1, y1, _, _ = boxes[index_of_driver].astype(int) \n",
        "    except:\n",
        "        pass\n",
        "    else:\n",
        "        cropped_img_yolo = frame[y0:y1, x0:x1]\n",
        "        img_age = pre_procces_for_age(cropped_img_yolo)\n",
        "        img_eye = pre_procces_for_eye(cropped_img_yolo)\n",
        "        img_emotion = pre_procces_for_emotion(cropped_img_yolo)\n",
        "\n",
        "\n",
        "        predicted_index_eye = np.argmax(eye_VGG16_tl.predict(img_eye))\n",
        "        predicted_index_age = np.argmax(age_model.predict(img_age))\n",
        "        predicted_emotion = emotion_model.predict(img_emotion)\n",
        "        predicted_index_emotion = np.argmax(predicted_emotion)\n",
        "        predicted_emotion_max = np.max(predicted_emotion)  \n",
        "        \n",
        "        crash_prob= 0.0\n",
        "        crash_prob += age_dictionary[predicted_index_age][1]\n",
        "        \n",
        "        if len(sleeping_queue)>= FPS*7:\n",
        "            sleeping_queue.pop(0)\n",
        "        \n",
        "        if len(drowsy_queue)>= FPS*5:\n",
        "            drowsy_queue.pop(0)\n",
        "        \n",
        "        sleeping_queue.append(eye_dictionary[predicted_index_eye])\n",
        "        drowsy_queue.append(eye_dictionary[predicted_index_eye]) \n",
        "        \n",
        "        \n",
        "        if len(drowsy_queue) >= FPS*3:\n",
        "            if drowsy_queue.count(\"Open\") < drowsy_queue.count(\"Close\") * 4:\n",
        "                cv2.putText(frame, \"Drowsy   : True\", (25, 130), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),thickness = 2)\n",
        "                crash_prob += 0.3\n",
        "            else:\n",
        "                cv2.putText(frame, \"Drowsy   : False\", (25, 130), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),thickness = 2)\n",
        "                \n",
        "        if len(sleeping_queue) == (FPS*5):\n",
        "            if drowsy_queue.count(\"Open\") < drowsy_queue.count(\"Close\") * 5:\n",
        "                crash_prob = 1.0\n",
        "\n",
        "\n",
        "    \n",
        "        driver_x = int(x0 + ((x1-x0)/2))-50\n",
        "\n",
        "        cv2.putText(frame, \"DRIVER\", (driver_x, y1-15), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),thickness = 3)\n",
        "        cv2.putText(frame, f'Eyes          : {eye_dictionary[predicted_index_eye]}', (25, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),thickness = 2)\n",
        "        cv2.putText(frame, f'Age Pred.     : {age_dictionary[predicted_index_age][0]}', (25, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),thickness = 2)\n",
        "\n",
        "        if predicted_emotion_max >= 0.8:\n",
        "            cv2.putText(frame, f'Emotion Pred. : {emotion_dictionary[predicted_index_emotion][0]}', (25, 95), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),thickness = 2)\n",
        "            crash_prob += emotion_dictionary[predicted_index_emotion][1]\n",
        "        else:\n",
        "           cv2.putText(frame, \"Emotion Pred. : Neutral\", (25, 95), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),thickness = 2)\n",
        "\n",
        "        cv2.putText(frame, f'Crash Prob.     : {crash_prob:.2f}', (25, 165), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),thickness = 2)\n",
        "\n",
        "        start_point = (x0, y0)\n",
        "        end_point = (x1, y1)\n",
        "        cv2.rectangle(frame, start_point, end_point, (0,255,0), 2)\n",
        "        writer.write(frame)\n",
        "        \n",
        "    if cv2.waitKey(1) & 0xFF == ord('a'):\n",
        "        break\n",
        "  \n",
        "# Close the window / Release webcam\n",
        "cap.release()\n",
        "writer.release()\n",
        "# De-allocate any associated memory usage \n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "skgSXp7eSFHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Download the output video to watch it.</p>"
      ],
      "metadata": {
        "id": "vaq9tdZVU2GW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>REFERENCES</h1>\n",
        "<p>[1] T. Danisman, I. M. Bilasco, C. Djeraba and N. Ihaddadene, \"Drowsy driver detection system using eye blink patterns,\" 2010 International Conference on Machine and Web Intelligence, 2010, pp. 230-233, doi: 10.1109/ICMWI.2010.5648121.</p>\n",
        "<p> [2] P. Viola and M. Jones, \"Rapid object detection using a boosted cascade of simple features,\" International Conference on Computer Vision and Pattern Recognition, CVPR 2001 </p>\n",
        "<p> [3] H.A. Rowley, S. Baluja and T. Kanade, \"Neural Network-Based Face Detection,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 20, pp. 23-38, http://vasc.ri.cmu.edu/NNFaceDetector, 1998. </p>\n",
        "<p> [4] S. Milborrow and F. Nicolls, \"Locating facial features with an extended active shape model,\" In D. Forsyth, P. Torr and A. Zisserman (eds.) ECCV 2008, Part IV. LNCS, vol. 5305, 504-513. Springer-Verlag, Heidelberg, 2008.</p>\n",
        "<p> [5] 21. T.F. Cootes, G.J. Edwards and C.J. Taylor, \"Active appearance models,\" In H. Burkhardt and B. Neumann, editors, 5th European Conference on Computer Vision, vol. 2, 484-498. Springer, Berlin, 1998.</p>\n",
        "<p> [6] W. Yang and Z. Jiachun, \"Real-time face detection based on YOLO,\" 2018 1st IEEE International Conference on Knowledge Innovation and Invention (ICKII), 2018, pp. 221-224, doi: 10.1109/ICKII.2018.8569109. </p>\n",
        "<p> [7] https://discover.data.vic.gov.au/dataset/crash-stats-data-extract</p>\n",
        "<p> [8] https://susanqq.github.io/UTKFace/</p>\n",
        "<p> [9] http://parnec.nuaa.edu.cn/_upload/tpl/02/db/731/template731/pages/xtan/ClosedEyeDatabases.html</p>\n",
        "<p> [10] https://www.kaggle.com/datasets/msambare/fer2013</p>\n",
        "<p> [11] https://www.crowdhuman.org/ </p>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wg811VU851T4"
      }
    }
  ]
}